{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "frGt-lVAQk50"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "from keras import backend as keras\n",
        "from keras.layers import *\n",
        "from keras.models import Model\n",
        "\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "from keras.applications.inception_resnet_v2 import preprocess_input, decode_predictions\n",
        "\n",
        "#from keras.preprocessing import image\n",
        "#from keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.utils import load_img\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "#from CNN_utils import *\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (13,13) # Make the figures a bit bigger"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBwEO-UTQmxs"
      },
      "source": [
        "base_model = InceptionResNetV2(include_top=True, weights='imagenet') #classes=1000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_nErJLpQ2Ma"
      },
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bounds(out, percentile=95):\n",
        "    # Get bounding box of 95+ percentile pixels\n",
        "    a = out.flatten()\n",
        "    filtered = np.array([1 if x > np.percentile(a, percentile) else 0 for x in a]).reshape(299,299)\n",
        "    left, up, down, right = 299, 299, 0, 0\n",
        "    for x in range(299):\n",
        "        for y in range(299):\n",
        "            if filtered[y,x] == 1:\n",
        "                left = min(left, x)\n",
        "                right = max(right, x)\n",
        "                up = min(up, y)\n",
        "                down = max(down, y)\n",
        "    return left, up, down, right\n",
        "\n",
        "def heatmap_for_top_pred(img2infer, model_CAM,  pred_index=None, figsizeX=12, analysed_preds=7):\n",
        "    img = load_img(img2infer, target_size=(299, 299))\n",
        "    x = img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = model_CAM(x)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(preds[0])\n",
        "        class_channel = preds[:, pred_index]\n",
        "        \n",
        "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    last_conv_layer_output = last_conv_layer_output[0]\n",
        "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "\n",
        "    heatmap = cv2.resize(heatmap.numpy(), (224,224))\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "    left, up, down, right = get_bounds(heatmap, percentile=95)\n",
        "\n",
        "    rect = patches.Rectangle((left, up), (right-left), (down-up), linewidth=1,  edgecolor='r', facecolor='none')\n",
        "\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(figsizeX, figsizeX))\n",
        "    axes.imshow(img, alpha=0.7)\n",
        "    axes.imshow(heatmap, cmap='jet', alpha=0.3)\n",
        "    left, up, down, right = get_bounds(heatmap, percentile=95)\n",
        "    rect = patches.Rectangle((left, up), (right-left), (down-up), linewidth=1,  edgecolor='r', facecolor='none')\n",
        "    axes.add_patch(rect)\n",
        "    axes.set_title('Heat map and bounding box for prediction: '+str(decode_predictions[0][analysed_preds][1]))\n",
        "    return None"
      ],
      "metadata": {
        "id": "IHJ75eFDCera"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpK_YTUVbCa9"
      },
      "source": [
        "def get_predictions(filename):\n",
        "  img = load_img(filename, target_size=(299, 299))\n",
        "\n",
        "  plt.figure()\n",
        "  plt.imshow(img)\n",
        "\n",
        "  x = img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  x = preprocess_input(x)\n",
        "\n",
        "  preds = base_model.predict(x)\n",
        "  # decode the results into a list of tuples (class, description, probability)\n",
        "  # (one such list for each sample in the batch)\n",
        "  decode_preds = decode_predictions(preds, top=1)\n",
        "\n",
        "  #print('Top 3 predictions:', decode_preds[0][0][1], decode_preds[0][1][1], decode_preds[0][2][1])\n",
        "  #decode_preds[0]\n",
        "\n",
        "  plt.title('Top prediction:'+ str(decode_preds[0][0][1]))\n",
        "  return str(decode_preds[0][0][1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcWWbHvyQ2Lo"
      },
      "source": [
        "try:\n",
        "  filename = take_photo()\n",
        "  #print('Saved to {}'.format(filename))\n",
        "  my_pred = get_predictions(filename)\n",
        "  # Show the image which was just taken.\n",
        "  #display(Image(filename))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-dG9GJ0aVO4"
      },
      "source": [
        "#base_model.summary()\n",
        "#heatmap_for_top_pred ('photo.jpg', base_model, figsizeX=12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer_index = 'conv_7b'\n",
        "model = Model(inputs=base_model.input, outputs=(base_model.get_layer(layer_index).output,base_model.layers[-1].output))"
      ],
      "metadata": {
        "id": "tuBxNe4TDnRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figsizeX = 15\n",
        "\n",
        "img = load_img(filename, target_size=(299, 299))\n",
        "x = img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    last_conv_layer_output, preds = model(x)\n",
        "    pred_index = tf.argmax(preds[0])\n",
        "    class_channel = preds[:, pred_index]\n",
        "    \n",
        "grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "\n",
        "pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "last_conv_layer_output = last_conv_layer_output[0]\n",
        "heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
        "heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "\n",
        "heatmap = cv2.resize(heatmap.numpy(), (299,299))\n",
        "heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "left, up, down, right = get_bounds(heatmap, percentile=95)\n",
        "\n",
        "rect = patches.Rectangle((left, up), (right-left), (down-up), linewidth=1,  edgecolor='r', facecolor='none')\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(figsizeX, figsizeX))\n",
        "axes.imshow(img, alpha=0.7)\n",
        "axes.imshow(heatmap, cmap='jet', alpha=0.3)\n",
        "left, up, down, right = get_bounds(heatmap, percentile=95)\n",
        "rect = patches.Rectangle((left, up), (right-left), (down-up), linewidth=1,  edgecolor='r', facecolor='none')\n",
        "axes.add_patch(rect)\n",
        "axes.set_title('Heat map and bounding box for prediction: '+ my_pred)\n"
      ],
      "metadata": {
        "id": "rVSr1d3RCQY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QeyxWVr2DU1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T4UIT0hbGSub"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}